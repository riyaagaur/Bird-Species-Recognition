# -*- coding: utf-8 -*-
"""buildAndTrainModel.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1B_LVUtotUMqmBh6GPWZXrwSHCqT3dRQe
"""

import pickle
import numpy as np
import tensorflow as tf
from datetime import datetime
import pandas as pd


data_dict = pickle.load(open("/content/dataset-v2.pkl", "rb"))
X = data_dict['X']
y = data_dict['y']

print(data_dict)

from tensorflow.train import BytesList,FloatList,Int64List
from tensorflow.train import Feature,Features,Example
from tensorflow.train import Example, Features, Feature

# Quantize fractional change of next hour's CAD-high versus previous hours CAD-close into 23 bins
bins = np.linspace(-0.001, 0.001, 21)
delta = (y - X['CAD-close']) / X['CAD-close']
X['bin_y'] = np.digitize(delta, bins)


# 7-valued categorical attribute indicating day of the week
X['weekday'] = X['date'].dt.weekday

# 24-valued categorical attribute indicating hour of the day
X['hour'] = X['date'].dt.hour

# 12-valued categorical attribute indicating month of the year
X['month'] = X['date'].dt.month - 1

ticker = X.columns[1:-4]

# converting Protobufs to tfrecords for each instance
with tf.io.TFRecordWriter('data-set.tfrecords') as f: 
  for instance in X.iterrows(): 
    example = {
    'tickers': Feature(float_list=FloatList(value=list(instance[1][ticker].values))),
    'weekday': Feature(int64_list=Int64List(value=[instance[1]['weekday']])),
    'hour': Feature(int64_list=Int64List(value=[instance[1]['hour']])),
    'month': Feature(int64_list=Int64List(value=[instance[1]['month']])),
    'target': Feature(int64_list=Int64List(value=[instance[1]['bin_y']]))
}
    myExamp = Example(features=Features(feature=example)) 
    f.write(myExamp.SerializeToString())

class ImputerLayer(tf.keras.layers.Layer):
    def __init__(self):
        super(ImputerLayer, self).__init__()

    def build(self, input_shape):
        self.mask = tf.logical_not(tf.math.is_nan(input_shape))
        super(ImputerLayer, self).build(input_shape)

    def call(self, inputs):
        mean = tf.reduce_mean(tf.boolean_mask(inputs, self.mask), axis=0)
        return tf.where(tf.math.is_nan(inputs), tf.broadcast_to(mean, inputs.shape), inputs)

    def compute_output_shape(self, input_shape):
        return input_shape

    def get_config(self):
        return super(ImputerLayer, self).get_config()

"""3.2

"""

import tensorflow as tf
from tensorflow.keras.layers import Input
from tensorflow import keras
from tensorflow.keras.layers.experimental import preprocessing

from tensorflow import keras
from tensorflow.keras.layers.experimental import preprocessing

# Define a new class for custom imputation layer
class ImputerLayer(keras.layers.Layer):
    def adapt(self, data):
        non_nan_data = tf.boolean_mask(data, tf.logical_not(tf.math.is_nan(data)))
        self.mean = tf.reduce_mean(non_nan_data, axis=0)

    def call(self, inputs):
        nan_mask = tf.math.is_nan(inputs)
        return tf.where(nan_mask, tf.fill(tf.shape(inputs), self.mean), inputs)

# Define a method to parse serialized example protobufs
def parse_example(example_proto):
    feature_description = {
        'tickers': tf.io.FixedLenFeature([188], tf.float32),
        'weekday': tf.io.FixedLenFeature([], tf.int64),
        'hour': tf.io.FixedLenFeature([], tf.int64),
        'month': tf.io.FixedLenFeature([], tf.int64),
        'target': tf.io.FixedLenFeature([], tf.int64),
    }
    example = tf.io.parse_single_example(example_proto, feature_description)
    features = {k: example[k] for k in example.keys() if k != 'target'}
    target = example['target']
    return features, target

# Load the dataset from the tfrecords file and batch it
batch_size = 200
tfrecords_dataset = tf.data.TFRecordDataset("data-set.tfrecords")
parsed_dataset = tfrecords_dataset.map(parse_example)
cached_dataset = parsed_dataset.cache()
batched_dataset = cached_dataset.batch(batch_size)

# Split the loaded dataset into training, validation, and testing datasets
train_size = int(0.7 * batch_size)
val_size = int(0.2 * batch_size)
test_size = batch_size - train_size - val_size
train_dataset = batched_dataset.take(train_size)
val_dataset = batched_dataset.skip(train_size).take(val_size)
test_dataset = batched_dataset.skip(train_size + val_size).take(test_size)

# Create a series of 4 keras inputs for the 4 labels in the instance dictionary
tickers_input = keras.Input(shape=(188,), dtype=tf.float32, name="tickers")
weekday_input = keras.Input(shape=(), dtype=tf.int64, name="weekday")
hour_input = keras.Input(shape=(), dtype=tf.int64, name="hour")
month_input = keras.Input(shape=(), dtype=tf.int64, name="month")

# Import the ImputerLayer, adapt it to the training data for the tickers attributes
imputer_layer = ImputerLayer()
for batch in train_dataset:
    tickers = batch[0]['tickers']
    imputer_layer.adapt(tickers)

# Create a Keras preprocessing normalization and adapt to output of the imputer applied to the training data for the tickers attributes
normalizer = preprocessing.Normalization()
for batch in train_dataset:
    tickers = batch[0]['tickers']
    imputed_tickers = imputer_layer(tickers)
    normalizer.adapt(imputed_tickers)

# The tickers input should feed into the ImputerLayer followed by the Normalizer
imputed_tickers = imputer_layer(tickers_input)
normalized_tickers = normalizer(imputed_tickers)
print(imputed_tickers)
print(normalized_tickers)

import tensorflow as tf
from tensorflow.keras.layers import Input, Embedding, Flatten, Concatenate, Dense, BatchNormalization

# Define input layers for the various features
num_tickers = 188
tickers_input = Input(shape=(1,), name='tickers_input')
weekday_input = Input(shape=(1,), name='weekday_input')
hour_input = Input(shape=(1,), name='hour_input')
month_input = Input(shape=(1,), name='month_input')

# Define embedding layers for the features
ticker_embedding = Embedding(input_dim=num_tickers, output_dim=16, name='ticker_embedding')(tickers_input)
weekday_embedding = Embedding(input_dim=7, output_dim=16, name='weekday_embedding')(weekday_input)
hour_embedding = Embedding(input_dim=24, output_dim=16, name='hour_embedding')(hour_input)
month_embedding = Embedding(input_dim=12, output_dim=16, name='month_embedding')(month_input)

# Flatten the embedding layers
ticker_flattened = Flatten()(ticker_embedding)
weekday_flattened = Flatten()(weekday_embedding)
hour_flattened = Flatten()(hour_embedding)
month_flattened = Flatten()(month_embedding)

# Normalize the tickers
tickers_normalized = BatchNormalization()(ticker_flattened)

# Stack the output of the embedding layers and the normalized tickers
stacked = Concatenate()([tickers_normalized, weekday_flattened, hour_flattened, month_flattened])
stacked = Dense(units=64, activation='relu')(stacked)

# Define the output layer
output_layer = Dense(units=1, activation='sigmoid')(stacked)

# Define the model
model = tf.keras.models.Model(inputs=[tickers_input, weekday_input, hour_input, month_input], outputs=output_layer)

import tensorflow as tf
from tensorflow import keras

class ImputerLayer(keras.layers.Layer):
    def __init__(self, **kwargs):
        super().__init__(**kwargs)

    def call(self, inputs):
        mask = tf.math.logical_not(tf.math.is_finite(inputs))
        mask = tf.cast(mask, tf.float32)
        mean = tf.reduce_mean(tf.where(tf.math.is_finite(inputs), inputs, tf.zeros_like(inputs)), axis=0)
        inputs = tf.where(tf.math.is_finite(inputs), inputs, tf.zeros_like(inputs) + mean)
        return inputs

    def get_config(self):
        return super().get_config()

    @classmethod
    def from_config(cls, config):
        return cls(**config)

weekday_input = keras.layers.Input(shape=(1,), dtype='int64', name='weekday_input')
hour_input = keras.layers.Input(shape=(1,), dtype='int64', name='hour_input')
month_input = keras.layers.Input(shape=(1,), dtype='int64', name='month_input')

# Define the architecture of model using TensorFlow and Keras
tickers_input = keras.Input(shape=(188,), dtype=tf.float32, name="tickers")
weekday_input = keras.Input(shape=(1,), dtype=tf.int64, name="weekday")
hour_input = keras.Input(shape=(1,), dtype=tf.int64, name="hour")
month_input = keras.Input(shape=(1,), dtype=tf.int64, name="month")
imputer_layer = ImputerLayer()
ticker_imputed = imputer_layer(tickers_input)
# convert to float32
weekday_input_float = keras.layers.Lambda(lambda x: tf.cast(x, 'float32'))(weekday_input)
hour_input_float = keras.layers.Lambda(lambda x: tf.cast(x, 'float32'))(hour_input)
month_input_float = keras.layers.Lambda(lambda x: tf.cast(x, 'float32'))(month_input)
x = keras.layers.Concatenate()([ticker_imputed, weekday_input_float, hour_input_float, month_input_float])
x = keras.layers.Dense(128, activation='relu')(x)
x = keras.layers.BatchNormalization()(x)
output = keras.layers.Dense(22, activation='softmax')(x)
model = keras.Model(inputs=[tickers_input, weekday_input, hour_input, month_input], outputs=output)

# Compile model
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Fit model to the training data
model.fit(train_dataset, epochs=20, validation_data=val_dataset, batch_size=250)

# Evaluate model on the test data
test_loss, test_acc = model.evaluate(test_dataset)

model.save('mysavedmodel.h5')