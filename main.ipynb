{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "\n",
    "def show_box(box, ax):\n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0,0,0,0), lw=2)) \n",
    "\n",
    "def show_boxes_on_image(raw_image, boxes):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(raw_image)\n",
    "    for box in boxes:\n",
    "      show_box(box, plt.gca())\n",
    "    plt.axis('on')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor, AutoModelForObjectDetection\n",
    "import torch\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def subSelectImages(paths):\n",
    "    if len(paths) == 0:\n",
    "        print(\"no filenames provided\")\n",
    "        return []\n",
    "    \n",
    "    yolo_processor = AutoImageProcessor.from_pretrained(\"hustvl/yolos-tiny\")\n",
    "    yolo_model = AutoModelForObjectDetection.from_pretrained(\"hustvl/yolos-tiny\")\n",
    "\n",
    "    dir_name = './images/birds'\n",
    "    paths = os.listdir(dir_name)[0: 100]\n",
    "    if '.DS_Store' in paths:\n",
    "        paths.pop(paths.index('.DS_Store'))\n",
    "    selected_filenames = []\n",
    "    for path in paths:\n",
    "        path = f'{dir_name}/{path}'\n",
    "        if not os.path.isfile(path):\n",
    "            print(f'{path} - file not found')\n",
    "            return\n",
    "        \n",
    "        raw_image = Image.open(path).convert(\"RGB\")\n",
    "        inputs = yolo_processor(images=raw_image, return_tensors=\"pt\")\n",
    "        outputs = yolo_model(**inputs)\n",
    "        target_sizes = torch.tensor([raw_image.size[::-1]])\n",
    "        results = yolo_processor.post_process_object_detection(outputs, threshold=0.5, target_sizes=target_sizes)[0]\n",
    "        print(f\"{path} - {results['labels']}\")\n",
    "\n",
    "        # labels = results['labels']\n",
    "        # if (16 in labels) or (17 in labels) or (18 in labels) or (23 in labels):\n",
    "        #     selected_filenames.append(path)\n",
    "        \n",
    "        # if len(selected_filenames) >= 5:\n",
    "        #     break\n",
    "\n",
    "    return selected_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./images/birds/bird-1.jpeg - tensor([16])\n",
      "./images/birds/bird-4.jpeg - tensor([85, 16, 16, 16])\n",
      "./images/birds/bird-5.jpeg - tensor([16, 16, 16])\n",
      "./images/birds/bird-2.jpeg - tensor([16, 16])\n",
      "./images/birds/bird-3.jpeg - tensor([16])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subSelectImages('jaj')\n",
    "\n",
    "# os.listdir('./images/all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import SamModel, SamProcessor\n",
    "from transformers import AutoImageProcessor, AutoModelForObjectDetection\n",
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "def segmentImages(paths):\n",
    "    if len(paths) == 0:\n",
    "        print(\"no filenames provided\")\n",
    "        return []\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    sam_model = SamModel.from_pretrained(\"facebook/sam-vit-huge\").to(device)\n",
    "    sam_processor = SamProcessor.from_pretrained(\"facebook/sam-vit-huge\")\n",
    "    yolo_processor = AutoImageProcessor.from_pretrained(\"hustvl/yolos-tiny\")\n",
    "    yolo_model = AutoModelForObjectDetection.from_pretrained(\"hustvl/yolos-tiny\")\n",
    "\n",
    "    dir_name = './images/squirrels'\n",
    "    paths = os.listdir(dir_name)\n",
    "    if '.DS_Store' in paths:\n",
    "        paths.pop(paths.index('.DS_Store'))\n",
    "    masks = ''\n",
    "    for index, path in enumerate(paths):\n",
    "        path = f'{dir_name}/{path}'\n",
    "        if not os.path.isfile(path):\n",
    "            print(f'{path} - file not found')\n",
    "            return\n",
    "        \n",
    "        raw_image = Image.open(path).convert(\"RGB\")\n",
    "        inputs = yolo_processor(images=raw_image, return_tensors=\"pt\")\n",
    "        outputs = yolo_model(**inputs)\n",
    "        target_sizes = torch.tensor([raw_image.size[::-1]])\n",
    "        results = yolo_processor.post_process_object_detection(outputs, threshold=0.5, target_sizes=target_sizes)[0]\n",
    "        if len(results['labels']) == 0:\n",
    "            print(f\"{path} - No squirrels detected\")\n",
    "        else:\n",
    "            print(f\"{path} - {results['labels']}\")\n",
    "\n",
    "            input_boxes = [np.ndarray.tolist(results[\"boxes\"].detach().numpy())]\n",
    "            inputs = sam_processor(raw_image, input_boxes=input_boxes, return_tensors=\"pt\").to(device)\n",
    "            image_embeddings = sam_model.get_image_embeddings(inputs[\"pixel_values\"])\n",
    "\n",
    "            inputs.pop(\"pixel_values\", None)\n",
    "            inputs.update({\"image_embeddings\": image_embeddings})\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = sam_model(**inputs)\n",
    "            masks = sam_processor.image_processor.post_process_masks(outputs.pred_masks.cpu(), inputs[\"original_sizes\"].cpu(), inputs[\"reshaped_input_sizes\"].cpu())\n",
    "            masked_image = []\n",
    "            for index, mask in enumerate(masks[0]):\n",
    "                if not (results['labels'][index].item() >= 85):\n",
    "                    masked_image = (masked_image == True) | (mask[:, :, :] == True)\n",
    "            masked_image = masked_image.float()\n",
    "            masks.append({'path': path, 'mask': masked_image})\n",
    "            masked_image = masked_image.permute(1, 2, 0)\n",
    "\n",
    "            # filename = path.split('/')[-1]\n",
    "            # mask_path = f'./birdmask-images/{filename}'\n",
    "            # mask_path = Path(mask_path)\n",
    "            # if not mask_path.is_file():\n",
    "            #     Path('birdmask-images').mkdir(parents=True, exist_ok=True)\n",
    "            # plt.imsave(f'./birdmask-images/masked_{filename}', masked_image.numpy())\n",
    "            # plt.imsave(f'./birdmask-images/{filename}', np.array(raw_image))\n",
    "\n",
    "\n",
    "            filename = path.split('/')[-1]\n",
    "            mask_path = f'./squirrelmask-images/{filename}'\n",
    "            mask_path = Path(mask_path)\n",
    "            if not mask_path.is_file():\n",
    "                Path('squirrelimages').mkdir(parents=True, exist_ok=True)\n",
    "            plt.imsave(f'./squirrelmask-images/masked_{filename}', masked_image.numpy())\n",
    "            plt.imsave(f'./squirrelmask-images/{filename}', np.array(raw_image))\n",
    "        \n",
    "    # plt.show()\n",
    "    return masks, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks, results_arr = segmentImages('fsa')\n",
    "\n",
    "# [os.listdir('./images/birds/')[2]]\n",
    "# len(torch.tensor([]))\n",
    "\n",
    "# './images/birds/bird-1.jpeg'.split('/')[-1]\n",
    "\n",
    "# './birdmask-images/masked_bird-1.jpeg'.replace('masked_', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imsave('./check.jpeg', torch.squeeze(masks[0]).permute(1, 2, 0).float().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_arr[0]['labels'] == 16\n",
    "# masks[0].float()\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "\n",
    "transform = T.ToPILImage()\n",
    "mask_image = transform(torch.squeeze(masks[0].float()))\n",
    "image = Image.open('./images/birds/bird-1.jpeg')\n",
    "prompt = \"change bird to a different kind of bird\"\n",
    "\n",
    "generateBirdFeederImagesFromText(prompt, image, mask_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from diffusers import StableDiffusionInpaintPipeline\n",
    "\n",
    "\n",
    "def generateBirdFeederImagesFromText(prompt, image, mask_image):\n",
    "    pipeline = StableDiffusionInpaintPipeline.from_pretrained(\"runwayml/stable-diffusion-inpainting\", torch_dtype=torch.float16)\n",
    "    # pipeline = pipeline.to(\"cuda\")\n",
    "\n",
    "    prompt = prompt\n",
    "    image = pipeline(prompt=prompt, image=image, mask_image=mask_image).images[0]\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor, AutoModelForObjectDetection\n",
    "import torch\n",
    "import os\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "\n",
    "def yolo(raw_image):\n",
    "    yolo_processor = AutoImageProcessor.from_pretrained(\"hustvl/yolos-tiny\")\n",
    "    yolo_model = AutoModelForObjectDetection.from_pretrained(\"hustvl/yolos-tiny\")\n",
    "\n",
    "    inputs = yolo_processor(images=raw_image, return_tensors=\"pt\")\n",
    "    outputs = yolo_model(**inputs)\n",
    "    target_sizes = torch.tensor([raw_image.size[::-1]])\n",
    "    results = yolo_processor.post_process_object_detection(outputs, threshold=0.5, target_sizes=target_sizes)[0]\n",
    "    return results\n",
    "\n",
    "\n",
    "def subSelectBirdImages(paths):\n",
    "    if len(paths) == 0:\n",
    "        print(\"empty input\")\n",
    "        return []\n",
    "    dir_name = './images/squirrels'\n",
    "    paths = os.listdir(dir_name)\n",
    "    if '.DS_Store' in paths:\n",
    "        paths.pop(paths.index('.DS_Store'))\n",
    "    selected_filenames = []\n",
    "    for path in paths:\n",
    "        path = f'{dir_name}/{path}'\n",
    "        if not os.path.isfile(path):\n",
    "            print(f'{path} - file not found')\n",
    "            return\n",
    "        \n",
    "        print(path)\n",
    "        raw_image = Image.open(path).convert(\"RGB\")\n",
    "        results = yolo(raw_image=raw_image)\n",
    "        labels = results['labels']\n",
    "        if (17 in labels) or (18 in labels) or (20 in labels) or (23 in labels) or (25 in labels) or (44 in labels) or (85 in labels) or (86 in labels):\n",
    "            selected_filenames.append(path)\n",
    "        \n",
    "        if len(selected_filenames) >= 5:\n",
    "            break\n",
    "    return selected_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subSelectBirdImages('sda')\n",
    "\n",
    "# raw_image = Image.open('./test.jpeg').convert(\"RGB\")\n",
    "# yolo(raw_image=raw_image)['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n",
      "100%|██████████| 50/50 [03:32<00:00,  4.25s/it]\n"
     ]
    }
   ],
   "source": [
    "from diffusers import StableDiffusionInpaintPipeline\n",
    "\n",
    "def stable_diffusion(prompt, raw_image, mask_image):\n",
    "    pipeline = StableDiffusionInpaintPipeline.from_pretrained(\"runwayml/stable-diffusion-inpainting\", torch_dtype=torch.float32, safety_checker = None,\n",
    "    requires_safety_checker = False)\n",
    "    pipeline.to('cuda')\n",
    "    image = pipeline(prompt=prompt, image=raw_image, mask_image=mask_image).images[0]\n",
    "    return image\n",
    "\n",
    "prompt = \"remove the mask area in the image and fill the area with background\"\n",
    "path = '../HW-3/sv695/squirrelmask-images/masked_squirrel-1.jpeg'\n",
    "raw_image = Image.open(path.replace('masked_', '')).convert(\"RGB\").resize((512, 512))\n",
    "masked_image = Image.open(path).convert(\"RGB\").resize((512, 512))\n",
    "squirrel_removed = stable_diffusion(prompt=prompt, raw_image=raw_image, mask_image=masked_image)\n",
    "\n",
    "rm_dir_name = './squirrels-removed'\n",
    "filename = path.split('/')[-1]\n",
    "mask_path = f'./{rm_dir_name}/{filename}'\n",
    "mask_path = Path(mask_path)\n",
    "if not mask_path.is_file():\n",
    "    Path(rm_dir_name).mkdir(parents=True, exist_ok=True)\n",
    "new_filename = f\"{filename.split('.jpeg')[0]}-squirrelsRemoved.jpeg\"\n",
    "plt.imsave(f'./{rm_dir_name}/{new_filename}', np.array(squirrel_removed))\n",
    "plt.imsave(f'./{rm_dir_name}/raw_image_of-{new_filename}', np.array(raw_image))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
